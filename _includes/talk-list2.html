<dl class="talks"><dt>Web Platform: a 30,000 feet view / Web Platform and JS environment constraints</dt><dd><dl><dt>Speaker</dt><dd>Dominique Hazaël-Massieux (W3C)</dd><dd>    Dominique is part of the full-time technical staff employed by W3C to animate the Web standardization work. He is in particular responsible for the work on WebRTC, WebXR and Web & Networks, led the effort to start a WebTransport Working Group and is one of the organizers of the Web and Machine Learning workshop.</dd><dt>Speaker</dt><dd>    Background talk on the specificities of the Web browser as a development platform.</dd></dl></dd>
<dt>Media processing hooks for the Web</dt><dd><dl><dt>Speaker</dt><dd>François Daoust (W3C)</dd><dd>François is part of the full-time technical staff employed by W3C and supervizes there the work related to media technologies.</dd><dt>Speaker</dt><dd>This talk will provide an overview of existing, planned or possible hooks for processing muxed and demuxed media (audio and video) in real time in Web applications, and rendering the results. It will also present high-level requirements for efficient media processing.</dd></dl></dd>
<dt>Access purpose-built ML hardware with Web Neural Network API</dt><dd><dl><dt>Speaker</dt><dd>Ningxin Hu (Intel)</dd><dd>Ningxin is a principal software engineer at Intel. Ningxin is co-editing the Web Neural Network (WebNN) API spec within W3C Machine Learning for the Web Community Group.</dd><dt>Speaker</dt><dd>The WebNN API is a new web standard proposal that allows web apps and frameworks to accelerate deep neural networks with dedicated on-device hardware such as GPUs, CPUs with deep learning extensions, or purpose-built AI accelerators. A prototype of WebNN API will be used to demonstrate the near-native speed of deep neural network execution for object detection by accessing AI accelerators on phone and PC.</dd></dl></dd>
<dt>A proposed web standard to load and run ML models on the web</dt><dd><dl><dt>Speaker</dt><dd>Jonathan Bingham (Google)</dd><dd>Jonathan is a web product manager at Google.</dd><dt>Speaker</dt><dd>The Model Loader API is a new proposal for a web standard to make it easy to load and run ML models from JavaScript, taking advantage of available hardware acceleration. The API surface is similar to existing model serving APIs (like TensorFlow Serving, TensorRT, and MXNet Model Server), and it is complementary to the Web NN graph API proposal as well as lower level WebGL and WebGPU APIs.</dd></dl></dd>
<dt>Accelerated graphics and compute API for Machine Learning - DirectML</dt><dd><dl><dt>Speaker</dt><dd>Chai Chaoweeraprasit (Microsoft)</dd><dd>Chai leads development of machine learning platform at Microsoft</dd><dt>Speaker</dt><dd>DirectML is Microsoft's hardware-accelerated machine learning platform that powers popular frameworks such as TensorFlow and ONNX Runtime. It expands the framework's hardware footprint by enabling high-performance training and inference on any device with DirectX-capable GPU</dd></dl></dd>
<dt>Accelerate ML inference on mobile devices with Android NNAPI</dt><dd><dl><dt>Speaker</dt><dd>Miao Wang (Google)</dd><dd>    Software Engineer for Android Neural Networks API</dd><dt>Speaker</dt><dd>The Android Neural Networks API (NNAPI) is an Android C API designed for running computationally intensive operations for machine learning on Android devices. NNAPI is designed to provide a base layer of functionality for higher-level machine learning frameworks, such as TensorFlow Lite and Caffe2, that build and train neural networks. The API is available on all Android devices running Android 8.1 (API level 27) or higher. Based on an app’s requirements and the hardware capabilities on an Android device, NNAPI can efficiently distribute the computation workload across available on-device processors, including dedicated neural network hardware (NPUs and TPUs), graphics processing units (GPUs), and digital signal processors (DSPs).</dd></dl></dd>
<dt>Heterogeneous parallel programming with open standards using oneAPI and Data Parallel C++</dt><dd><dl><dt>Speaker</dt><dd>Jeff Hammond (Intel)</dd><dd>Jeff Hammond is a Principal Engineer at Intel where he works on a wide range of high-performance computing topics, including parallel programming models, system architecture and open-source software. He has published more than 60 journal and conference papers on parallel computing, computational chemistry, and linear algebra software. Jeff received his PhD in Physical Chemistry from the University of Chicago.</dd><dt>Speaker</dt><dd>Diversity in computer architecture and the unceasing demand for application performance in data-intensive workloads are never-ending challenges for programmers. This talk will describe Intel’s oneAPI initiative, which is an open ecosystem for heterogeneous computing that supports high-performance data analytics, machine learning and other workloads. A key component of this is Data Parallel C++, which is based on C++17 and Khronos SYCL and supports direct programming of CPU, GPU and FPGA platforms. We will describe how oneAPI and Data Parallel C++ can be used to build high-performance applications for a range of devices.</dd></dl></dd>
<dt>Enabling Distributed DNNs for the Mobile Web Over Cloud, Edge and End Devices</dt><dd><dl><dt>Speaker</dt><dd>Yakun Huang & Xiuquan Qiao (BPTU)</dd><dt>Speaker</dt><dd>    This talk introduces two deep learning technologies for the mobile web over cloud, edge and end devices. One is an adaptive DNN execution scheme, which partitions and performs the computation that can be done within the mobile web, reducing the computing pressure of the edge cloud. The other is a lightweight collaborative DNN over cloud, edge and devices, which provides a collaborative mechanism with the edge cloud for accurate compensation.</dd></dl></dd>
<dt>Collaborative Learning</dt><dd><dl><dt>Speaker</dt><dd>Wolfgang Maß (DFKI)</dd><dd>    Professor at Saarland University and scientific director at DFKI</dd><dt>Speaker</dt><dd>    The execution of data analysis services in a browser on devices has recently gained momentum, but the lack of computing resources on devices and data protection regulations are forcing strong constraints. In our talk we will present a browser-based collaborative learning approach for running data analysis services on peer-to-peer networks of devices. Our platform is developed in Javascript, supports modularization of services, model training and usage on devices (tensorflow.js), sensor communication (mqtt), and peer-to-peer communication (WebRTC) with role-based access-control (oauth 2.0).</dd></dl></dd>
<dt>Introducing WASI-NN</dt><dd><dl><dt>Speaker</dt><dd>Mingqiu Sun & Andrew Brown (Intel)</dd><dd>    Senior PE at Intel & software engineer at Intel</dd><dt>Speaker</dt><dd>    Trained machine learning models are typically deployed on a variety of devices with different architectures and operating systems. WebAssembly provides an ideal portable form of deployment for those models. In this talk, we will introduce the WASI-NN initiative we have started in the WebAssembly System Interface (WASI) community, which would standardize the neural network system interface for WebAssembly programs.</dd></dl></dd>
</dl>